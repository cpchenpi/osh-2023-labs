# Lab3实验报告

## 编译和运行方法

本次实验使用Cargo创建Rust语言项目，编译、运行方式与一般Cargo项目相同，在lab3目录下运行`cargo build`/`cargo run`即可。

EDIT：线程池部分直接在一开始的简单多线程项目上做了修改；然而对于主程序`main.rs`，这一修改不大。倘若要改回原来的简单多线程，直接将其中进程池的创建`ThreadPool::new`删去，并将向线程池发送任务`pool.send`改回原来的直接创建线程`thread.spawn`即可。

## 整体设计

> Rust团队认为高并发场景也是Rust语言的设计面向场景之一。因此，在Rust语言的官方教程([the book](https://doc.rust-lang.org/book/))和诸多第三方教程中，都将实现一个多线程服务器作为一个重要的教学项目。本实验参考了the book中的部分设计、思想和技术。

与提供的C语言项目类似，本项目也是从一开始的一个简易单线程服务器原型开始，逐步重构、发展的。初始项目的逻辑如下：
- 使用一个死循环处理到来的每一个请求
- 简单解析请求，判断状态码
- 发送状态码对应状态行，之后不再发送任何内容

这个项目只比示例项目略胜一筹（进行了简单的状态码判断）：Rust标准库为我们避免了大量的底层操作，让我们可以分出更多的精力在任务本身之上。当然，示例程序的缺点这个程序一样都有。接下来，以必做部分给出的四个任务（四个小标题）为指引，改进本项目。

### 并发请求处理

分析本实验的要求，我们发现可以直接对每个请求创建一个线程，仍然调用之前的函数，不会发生并发问题。这是因为不同进程处理不同请求，不会产生先后顺序上的冲突，也不涉及到线程间的相互通信、共享数据等（这一点在选做部分会被打破）。

### 解析和检验HTTP头

首先，我们设计一个抽象类`InputHandler`，负责接收数据，并解析出路径。收到的HTTP请求可能是畸形的，因此我们的解析函数返回`Result<String, E>`类型。函数的检验工作如下：
- 在第一个空行前是否至少有一行；
- 第一行是否恰好为三个单词；
- 第一个单词是否为"GET"，第三个单词是否为"HTTP/1.0"；
- 这个路径是否尝试跳出项目主目录。

在确认通过这些测试后，函数才返回一个代表路径的字符串。

之后这个路径会被用于进一步解析响应码。这一项工作由结构体`Status`的构造函数完成；构造函数运行完成后，结构体将包含状态码和路径本身。根据要求描述，构造函数的工作如下：
- 若前一个检验函数返回错误值，状态应为500；
- 若请求路径不存在，状态为404；
- 若路径为目录，状态也为500；
- 否则，状态为200。

至此，所有的解析、检验工作已经完成。

### 实现读取请求资源内容

状态码不为200时，后续内容为空，只要像示例程序一样返回即可。

状态码为200时，需要返回文件的内容。由于请求可能为二进制文件，我们应该以二进制形式读取文件，之后写入到TCP流之中。

这个过程不能直接使用`std::fs::read`等等尝试一次读入全部内容的函数。多数情况下，它有机会完成全部内容的读取，但在多线程、大文件的情况下，这会快速耗尽内存，使程序被系统杀死。

因此，我们采用有缓冲区的(buffered)I/O，在Rust中，标准库为我们提供了`BufReader`和`BufWriter`两个类型处理。需要注意的是，就算采用了缓冲区，也不能假定一次可以读/写完缓冲区内的数据，仍然要循环处理。

本实验中，我给每个线程分配了64K大小的缓冲区（仅对1M左右文件大小而言，再提高缓冲区大小的边际效应已经不高），尽量避免多次在读写过程间切换，同时也不至于占用过多内存（siege最多能够同时发送255个请求，因此占用内存在16M左右；实际测试也认为占用内存极小）。

### 实现错误和异常处理

在本实验中，我们可以看到绝大多数错误都局限在单个连接中，不应因此结束整个程序，因此我们在绝大多数地方采用`Result<T, E>`，而不直接`panic!`。

Rust语言为我们提供了优美的错误处理方式。其中最方便的一个模式叫做"传播错误"。它允许在一个函数中每当错误发生时直接结束当前函数的运行，将错误进一步返回上一级处理，只需要使用"?"运算符。

使用该模式，当大多数错误发生时，我们将其传播到上一级，并最后在主逻辑中统一判断。对所有的错误，我们都在标准错误流中输出它，并视发生场合的不同进行不同的处理：
- 在连接中或写入的错误直接丢弃并关闭连接（这样的错误大多情况下是不可恢复的）。
- 在读取或解析中发现的错误，无论原因，我们都应该尝试向用户返回500状态码（这部分逻辑在上面已经提到了）。

## 正确性与性能测试

> 测试环境：VMWare 虚拟机；
Ubuntu 18.04.6 LTS 64位，内存 8GB，处理器11th Gen Intel® Core™ i5-11400H @ 2.70GHz × 4 。


我们找来了各种大小的文件，并最终选择了5个文件用于测试，大小量级分别为5KB、100KB、1MB、50MB、500MB。

首先对五个文件分别进行正确性测试；这里我们选择使用`curl`从服务器获取文件，并使用`cmp`命令与本地文件比较，经检验通过了所有测试，在此不再附图片。

接下来进行性能测试。为了更接近较高并发场景，在能带动的情况下尽量使用最高并发数；为了控制测试时间相近，测试轮数与每轮数据量负相关。对五个文件测试得到数据如下：（由于在虚拟机环境下测试，可能与实际情况不同）

| 文件大小 | 并发数 | 轮数 | 总用时(s) | 可用性 | 吞吐量(MB/s) | 并发能力 | 最长传输时间 |
| :-----: | :---: | :-: | :------: | :---: | :---------: | :-----: | :-------: |
| 5KB     | 255   | 256 | 5.31     | 100%  | 56.07       | 208.22  | 3.04      |
| 100KB   | 255   | 216 | 5.36     | 100%  | 1465.98     | 212.92  | 3.09      |
| 1MB     | 255   | 64  | 6.35     | 100%  | 3240.01     | 197.10  | 3.05      |
| 50MB    | 255   | 8   | 5.54     | 100%  | 3755.81     | 217.66  | 2.99      |
| 500MB   | 8     | 6   | 7.58     | 100%  | 3512.91     |   7.84  | 1.50      |

> 注：最后一组测试情况相对特殊：对于500MB的大文件，我的服务器本身没有出现问题，但只要并发数稍高，siege就会占用大量资源，很快被操作系统杀死，因此只能运行较小的测试。

观察测试数据，我们得到以下结论：
- 在文件大小较小时，很显然吞吐率并不高，这是由于此时程序的运行瓶颈不在传输文件本身，而在对每个请求创建线程、处理请求等开销上。
- 在文件内存增大时，吞吐率很快增大并在达到一个范围后保持相对稳定。可以认为，此时它已经达到了吞吐率上界。
- 服务器的并发数波动不定，但总体来说达不到255的上限。就算对于相对较大的文件，最长传输用时仍保持相对稳定。

## 选做内容

### 使用线程池机制

线程池机制，指不对每个请求单独创建新的线程，而是预先创建一批线程，每个请求到来时分配给它们处理。

线程池的机制可以避免重复创建和回收线程的开销。另外，如果遇到DoS攻击，可以确保线程数量有限而不至于占用系统过多资源，不像之前的版本会快速耗尽资源。

进行抽象：在本例中，线程池实际上是一个单生产者多消费者模型。对到来的每一个请求，程序主循环会将其发送给线程池中所有线程；线程池中所有线程在空闲时都会尝试获取任务并执行。

对于生产者消费者问题，Rust语言明确建议我们使用标准库提供的管道`mpsc::channel`。然而，Rust提供的管道是一个多生产者单消费者模型，正好与我们的需求相反。为了实现多消费者，我们需要对管道的接收端手动加锁`Mutex`；由于Rust特殊的所有权机制，对互斥锁我们还要包装一层原子（线程安全）引用计数`Arc`。

为了使得代码结构清晰，并方便使用，我们将这样的一个线程池模型封装为一个类型`ThreadPool`，对外提供插入任务的接口。

与上面的相同，对这个使用线程池的服务器进行测试，得到表格如下：

| 文件大小 | 并发数 | 轮数 | 总用时(s) | 可用性 | 吞吐量(MB/s) | 并发能力 | 最长传输时间 |
| :-----: | :---: | :-: | :------: | :---: | :---------: | :-----: | :-------: |
| 5KB     | 255   | 256 | 2.97     | 100%  | 100.24      | 191.54  | 1.03      |
| 100KB   | 255   | 216 | 4.46     | 100%  | 1761.81     | 218.70  | 0.71      |
| 1MB     | 255   | 64  | 5.67     | 100%  | 3628.58     | 219.55  | 1.00      |
| 50MB    | 255   | 8   | 5.85     | 100%  | 3556.78     | 179.67  | 2.58      |
| 500MB   | 8     | 6   | 7.76     | 100%  | 3431.43     |   7.92  | 1.56      |

可以看到，对于相对较小（1MB数量级以内）的文件，线程池机制对用时、吞吐量、最长延时等参数有很明显的提升。当然，对于较大的文件，线程池的表现相比之前没有明显的差异。一方面，我们的线程池实现的不够完善（Java语言就内置了十分复杂、完善的线程池）；另一方面，程序触碰到了硬件瓶颈；最后线程池导致的频繁等待、获取互斥锁等额外操作反而一定程度上拖慢了程序。

当然，HTTP会请求各种不同大小的文件，使用者可能有浏览网页、下载文件等用途。一般情况下，一个普通网络服务器的相当一部分请求是html、css、javascript等不会太大文件，所以对相对较小文件请求的性能提升是有必要的。

